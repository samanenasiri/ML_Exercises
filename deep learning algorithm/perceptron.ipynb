{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5613833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "162329f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbytes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "f = gzip.open('train-images-idx3-ubyte.pickle', 'rb')\n",
    "if sys.version_info < (3,):\n",
    "    data = pickle.load(f)\n",
    "else:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "f.close()\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43054e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "if sys.version_info < (3,):\n",
    "    data = pickle.load(f)\n",
    "else:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "f.close()\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aaf8ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"X_train shape\", x_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", x_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73d5273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 28, 28)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# Build a simpl1e model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.experimental.preprocessing.Rescaling(scale=1.0/255, input_shape=(28, 28)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "plot_model(model,to_file='multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "83d56a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit on NumPy data\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 0.2524 - sparse_categorical_accuracy: 0.9255\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0331 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9932\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9940\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "print(\"Fit on NumPy data\")\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a8e6fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0949 - sparse_categorical_accuracy: 0.9789 - 722ms/epoch - 2ms/step\n",
      "[0.09488321840763092, 0.9789000153541565]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0561399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for 3 samples\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predictions shape: [7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:5])\n",
    "print(\"predictions shape:\", np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b83ef220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(x_test[i], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(np.argmax(predictions[i])))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we use the \"sparse_categorical_cross\n",
    "entropy\" loss because we have sparse labels ( for each instance, there is just a tar‐\n",
    "get class index, from 0 to 9 in this case), and the classes are exclusive.\n",
    "\n",
    "If instead wehad one target probability per class for each instance (such as one-hot vectors, e.g.\n",
    "[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would\n",
    "need to use the \"categorical_crossentropy\" loss instead.\n",
    "\n",
    "If we were doing binary classification (with one or more binary labels), then we would use the \"sigmoid\" (i.e.,\n",
    "logistic) activation function in the output layer instead of the \"softmax\" activation\n",
    "function, and we would use the \"binary_crossentropy\" loss.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b0614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bdb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cfdf9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a990d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f7c44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0777 - val_loss: 5.0642\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6305 - val_loss: 0.4873\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 0.4386\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4215\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4210\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4041\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.3932\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.3930\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.4331\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.3897\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3901\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.3779\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3646 - val_loss: 0.3892\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.5031\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3766\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3719\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.3718\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3733\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3835\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3637\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3633\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "829e18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d04945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
